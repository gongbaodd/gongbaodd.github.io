{"posts":[{"id":"2020/06/06/Python.md","slug":"2020/06/06/python","body":"\n# 读「Python 深度学习」数学基础\n\n- 「学习」是指找到一组模型参数，使给定的训练数据样本和对应目标上的损失函数最小化。\n- 学习的过程：随机取包含数据样本及其目标值的批量，并计算批量损失相对于网络参数的梯度（梯度可以理解为对于张量计算的倒数）。随后将网络参数沿着梯度的反方向稍稍移动（移动距离由学习率指定）。\n- 整个学习过程之所以能够实现，是因为神经网络是一系列可微分的张量运算，因此可以使用求导的链式法则来得到梯度函数，这个函数将当前参数和当前数据批量映射为一个梯度值。\n- 「损失」是训练过程中需要最小化的量，因此它能够衡量当前任务是否已经成功解决。\n- 「优化器」是损失梯度更新参数的具体方式，比如 RMSProp 优化器，带动量的随机梯度下降（SGD）等。\n","collection":"blog","data":{"type":"post","category":"book","tag":["tensorflow"],"series":{"slug":"learn-tensorflow","name":"张量麻辣烫"}}},{"id":"2020/06/07/WSL2-Keras.md","slug":"2020/06/07/wsl2-keras","body":"\n# 在 WSL2 安装 Keras 及其依赖\n\n## 安装 python\n\n首先安装 python3 和 pip3，并且使用 USTC 源。\n\n```shell\nsudo apt install python3 python3-pip python3-dev\npip3 install -i https://mirrors.ustc.edu.cn/pypi/web/simple pip -U\npip3 config set global.index-url https://mirrors.ustc.edu.cn/pypi/web/simple\n```\n\n## 安装 python 科学套件\n\n1. 安装 BLAS 库（OpenBLAS），确保可以在 CPU 上面做张量运算。\n\n   ```shell\n   sudo apt install build-essential cmake git unzip pkg-config libopenblas-dev liblapack-dev\n   ```\n\n2. 安装 Python 科学套件：Numpy、SciPy 和 Matplotlib。这是做科学计算必须的。\n\n   ```shell\n    sudo apt install python3-numpy python3-scipy python3-matplotlib python3-yaml\n   ```\n\n3. 安装 HDF5，最初由 NASA 开发，用于保存数值数据的大文件。它可以帮助 Keras 模型快速高效保存到磁盘。\n\n   ```shell\n    sudo apt install libhdf5-serial-dev python3-h5py\n   ```\n\n4. 安装 Graphviz 和 pydot-ng，这两个包用于可视化 Keras 模型。并不是必须的。\n\n   ```shell\n    sudo apt install graphviz\n    pip3 install pydot-ng\n   ```\n\n5. 安装 tensorflow\n\n   ```shell\n   pip3 install tensorflow\n   pip3 install tensorflow-gpu\n   ```\n\n## 安装 Keras\n\n使用 pip3 安装 Keras。\n\n```shell\npip3 install keras\n```\n\n可以从 GitHub 中下载 Keras 的例子\n\n```shell\ngit clone https://github.com/keras-team/keras.git\n```\n\n测试一个例子\n\n```shell\npython3 mnist_cnn.py\n```\n\n执行成功后会在`~/.keras/keras.json`生成配置文件。\n","collection":"blog","data":{"type":"post","category":"book","tag":["tensorflow","keras","wsl2","python"],"series":{"slug":"learn-tensorflow","name":"张量麻辣烫"}}},{"id":"2020/06/08/Keras.md","slug":"2020/06/08/keras","body":"\n# Keras 分类问题-电影评论分类\n\n> 「Python 深度学习」的例子在[GitHub](https://github.com/fchollet/deep-learning-with-python-notebooks)上。\n> 别问我为啥不写在 notebook 上，等我心情好就给网站加一下这给你功能吧\n\n本文的 notebook 在[这个连接](https://github.com/gongbaodd/keras_study/blob/master/3.5%20movie%20reviews.ipynb)。\n\n将 IMDB 上的 50000 条两极分化的评论，一般用于训练，一半用于测试。这些数据中 data 是词索引组成的二维数组，每一行对应每条评论，label 为 0\\1 数组，0 表示负面评论，1 表示积极评论。\n\n## 处理数据\n\n```py\nimport keras\nfrom keras.datasets import imdb\n\n(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 1000)\n```\n\n数据集里面的数字可以解析成评论，每一个`data`都是如`[0, 14, 32, 56...]`的数组。\n\n```py\nword_index = imdb.get_word_index()\nreverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\ndecoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n```\n\n使用以下方法即可以把训练数据处理成 0/1 二维张量。\n\n```py\nimport numpy as np\n\ndef vectorize_sequences(sequences, dimension=10000):\n    results = np.zeros((len(sequences), dimension))\n    for i, sequence in enumerate(sequences):\n        results[i, sequence] = 1\n    return results\n\nx_train = vectorize_sequences(train_data)\nx_test = vectorize_sequesnces(test_data)\n\ny_train = np.array(train_labels).astype('float32')\ny_test = np.array(test_labels).astype('float32')\n```\n\n简单地说，x 值为 25000\\*10000 的二维数组，某个单词出现则在它所在的评论序号和对应的单词索引的位置上赋值 1，而 y 对应每个 x 行评论的正负反馈。\n\n## 构建网络\n\n使用 rlu 激活（线性整流函数 `max(0, input)`）的全链接层(Dense)就能很好处理这种输入值为标量和向量的情况，如`Dense(16, activation='relu')`。前面的 16 是一个隐藏单元，表示会将数据表示在一个 16 维的表示空间中，隐藏单元越高，能够学到的网络越复杂，计算代价也越大，但并不是越高越好，往往高了会学到不正确的模式。\n\n两个中间网络，第三层使用 sigmoid 激活（s 函数）以输出 0~1 的值\n\n![S函数](https://wikimedia.org/api/rest_v1/media/math/render/svg/a26a3fa3cbb41a3abfe4c7ff88d47f0181489d13)\n\n```py\nfrom keras import models\nfrom keras import layers\nfrom keras import optimizers\nfrom keras import losses\nfrom keras import metrics\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=optimizers.RMSprop(lr=0.001),\n              loss=losses.binary_crossentropy,\n              metrics=[metrics.binary_accuracy])\n```\n\n编译网络需要选择损失函数和优化器，这里是个二分类问题，网络最终输出一个概率值，所以最好使用 binary_crossentropy（二元交叉熵），优化器在这里选择 rmsprop。\n\n## 验证模型\n\n现在取训练数据的前 10000 条作为训练，并取后 10000 条做验证数据，20 个轮次，每次使用 512 个样本训练。\n\n```py\nx_val = x_train[:10000]\npartial_x_train = x_train[10000:]\n\ny_val = y_train[:10000]\npartial_y_train = y_train[10000:]\n\nhistory = model.fit(\n  partial_x_train,\n  partial_y_train,\n  epochs=20,\n  batch_size=512,\n  validation_data=(x_val, y_val)\n)\n```\n\n我们可以使用 history 这个变量绘制每次训练的精确度以及损失值变化。训练的损失会随着轮次减少，而验证则不然，大概训练到第 4 次能够拿到理想的结果。\n\n## 预测结果\n\n```py\nmodel = models.Sequential()\nmodel.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\nmodel.add(layers.Dense(16, activation='relu'))\nmodel.add(layers.Dense(1,  activation='sigmoid'))\n\nmodel.compile(\n    optimizer='rmsprop',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.fit(\n    x_train,\n    y_train,\n    epochs=4,\n    batch_size=512\n)\nresults = model.evaluate(x_test, y_test) # [0.3345052400302887, 0.8581200242042542]\n\nmodel.predict(x_test)\n```\n\n使用`predict`既可预测测试数据的正负反馈了。\n\n```py\narray([[0.3796336 ],\n       [0.996838  ],\n       [0.667047  ],\n       ...,\n       [0.11539856],\n       [0.14184406],\n       [0.47513008]], dtype=float32)\n```\n\n## 多分类问题\n\n书中还介绍了路透社新闻分类，不同点是构建网络时选用单元比较多（书中选择 64 维，因为有 46 个分类），最后一层激活函数选择`softmax`函数，它能保证这 46 个类的概率和为 1.\n\n最终编译时应选择`categorical_crossentropy`做损失函数。\n","collection":"blog","data":{"type":"post","category":"book","tag":["tensorflow","keras","wsl2","python"],"series":{"slug":"learn-tensorflow","name":"张量麻辣烫"}}},{"id":"2020/06/10/Keras.md","slug":"2020/06/10/keras","body":"\n# Keras 回归问题-预测房价\n\n回归问题用于预测一个连续值而不是离散值，如预测明天气温或者软件完成需要的时间。\n\n这个例子是要预测 20 世纪 70 年代中期波士顿郊区房价的中位数。\n\n## 获取数据\n\n```py\nfrom keras.datasets import boston_housing\n\n(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()\n```\n\n得到的训练数据`train_data`是一个 404x13 张量，测试数据为 102x13 张量，这 13 项包括：\n\n- 总犯罪率\n- 超过 25000 平方英尺的住宅比例\n- 非商用地比例\n- charles river 变量（1 或 0）\n- 氮氧化物浓度\n- 公寓房间数\n- 建于 1940 年前建筑的占有量\n- 到五个波士顿就业中心的加权平均值\n- 放射状公路可达指数\n- 每 \\$1000 的物业税\n- 城镇学生教师比例\n- 1000(Bk – 0.63)^2，城镇黑人占有率\n- 低收入人群占有率\n\n```py\ntrain_data[0]\n# array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n#       -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n#        1.14850044,  0.44807713,  0.8252202 ])\n```\n\n`train_targets` 对应房价，单位为千美元。\n\n```py\ntrain_targets\n# array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,...\n```\n\n## 准备数据\n\n对于这 13 种数据，取值范围不统一，这里要做取值的标准化，简单上讲让每个特征减去其平均值并除以标准差，这样，每个特征值都会取值于 0 左右，和统一的标准差。\n\n```py\nmean = train_data.mean(axis=0)\ntrain_data -= mean\nstd = train_data.std(axis=0)\ntrain_data /= std\n\ntest_data -= mean\ntest_data /= std\n```\n\n这里使用训练数据的平均值，这是不对的，但是书里面就这么写，我靠。\n\n## 创建网络\n\n```py\nfrom keras import models\nfrom keras import layers\n\ndef build_model():\n    model = models.Sequential()\n    model.add(layers.Dense(64, activation='relu',\n                          input_shape=(train_data.shape[1],)))\n    model.add(layers.Dense(64, activation='relu'))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n    return model\n```\n\n网络最后一层只有一个单元，没有激活，这是标量回归。最后一层的激活函数用于限定输出值的范围，如果是 sigmoid 函数，则输出 0-1 的值，如果最后一层为纯线性层，则可以预测任意范围的值。\n\n编译网络使用 mse 损失函数，即均方误差（mean squared error），预测值和目标值差的平方。训练的指标为 mae 平均绝对误差（mean absolute error），目标值和预测值差的绝对值。如果 MAE 值为 0.5 则代表预测房价与实际房价平均相差 500 美元。\n\n## 利用 K 折验证\n\n因为数据集比较小，可以使用 K 折验证，即把数据分为几分区（一般 4~5 组），最终取几个分区的平均值。\n\n```py\nimport numpy as np\n\nk = 4\nnum_val_samples = len(train_data) // k\nnum_epochs = 100\nall_scores = []\nfor i in range(k):\n    print('processing fold #', i)\n    # Prepare the validation data: data from partition # k\n    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n\n    # Prepare the training data: data from all other partitions\n    partial_train_data = np.concatenate(\n        [train_data[:i * num_val_samples],\n         train_data[(i + 1) * num_val_samples:]],\n        axis=0)\n    partial_train_targets = np.concatenate(\n        [train_targets[:i * num_val_samples],\n         train_targets[(i + 1) * num_val_samples:]],\n        axis=0)\n\n    # Build the Keras model (already compiled)\n    model = build_model()\n    # Train the model (in silent mode, verbose=0)\n    model.fit(partial_train_data, partial_train_targets,\n              epochs=num_epochs, batch_size=1, verbose=0)\n    # Evaluate the model on the validation data\n    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n    all_scores.append(val_mae)\n```\n\n这样获得值如下，2.1~2.6 不等。\n\n```py\nall_scores\n# [2.1905605792999268,\n#  2.4371392726898193,\n#  2.3653202056884766,\n#  2.5255486965179443]\n```\n\n如果想让数据更精确，不如让训练次数从 100 增加到 500，但是书里面最终的数据到 80 就差不多过拟合了，再加上我的笔记本跑不起来 500 次，这里就算了吧。。。\n\n## 预测\n\n```py\nmodel = build_model()\nmodel.fit(train_data, train_targets,\n          epochs=80, batch_size=16, verbose=0)\ntest_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n```\n\n最后预测的房价和现实房价相差大概 2714 美刀（书里预测的是 2550）.\n","collection":"blog","data":{"type":"post","category":"book","tag":["tensorflow","keras","wsl2","python"],"series":{"slug":"learn-tensorflow","name":"张量麻辣烫"}}},{"id":"2020/06/14/ml5.js-tensorflow.js.md","slug":"2020/06/14/ml5js-tensorflowjs","body":"\n# ml5.js 和 tensorflow.js，终于聊到前端部分了\n\n既然在浏览器中也可以计算多维数组，拿浏览器做深度学习也可以理解了。Google 给浏览器中设计了 [tensorflow.js](https://www.tensorflow.org/js)，跟 python 下面的 tensorflow 是同一套 API。又有一群人在 tensorflow 的基础上封装了一套[ml5.js](https://ml5js.org/)。对比 tensorflow.js，ml5.js 去掉了很多张量计算的部分（说实话，这些东西真不是人学的，我这一周都在研究这些计算...）。所以本文会以 ml5.js 开始。\n\n## ml5.js\n\n这是[Daniel Shiffman](http://www.shiffman.net/)主导的 JS 深度学习库，我特喜欢看他的视频睡觉。这个库的[使用教程](https://learn.ml5js.org/docs/#/reference/index)不能更详细了！\n\n官网的简介，是使用 MobileNet 了`imageClassifier`，这是我的[笔记](https://observablehq.com/@gongbaodd/untitled)，可以用来判断图片、视频中的物体是什么。\n\n另外也可以使用`neuralNetwork`，这是[笔记](https://observablehq.com/@gongbaodd/ml5-js-neural-network)，基本上前面两篇关于 tensorflow 的文章都可以使用它来跑。\n\n使用 ML5.js 很大的简化了 tensorflow 的 API，然而并不是你可以不了解 tensorflow，因为期间会有很多参数难以理解，又不得不回头看它。\n\n## tensorflow.js\n\n基本上会了 python 版本，js 版本就算是个子集了，基本上很多需要的包都有替代。[这里](https://www.tensorflow.org/js/guide/layers_for_keras_users?hl=zh-cn)是一个给 keras 用户使用的 tensorflow.js 指南。另外去强烈建议看看[tensorflow.js 指南](https://www.tensorflow.org/js/guide?hl=zh-cn)。\n\n- `tf.layers` => Keras\n- `@tensorflow/tfjs-vis`原生支持 tensorflow 的数据可视化库（那敢情好啊）\n","collection":"blog","data":{"type":"post","category":"fe","tag":["tensorflow","keras","wsl2","python"],"series":{"slug":"learn-tensorflow","name":"张量麻辣烫"}}}]}