<!DOCTYPE html><html lang="en" class="h-full relative" data-astro-cid-d3haqyqs><head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v3.5.0"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="manifest" href="/site.webmanifest"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><!-- Font preloads --><!-- <link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin />
<link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin /> --><!-- Canonical URL --><link rel="canonical" href="https://growgen.xyz/tech/2020/02/04/windows-scrapy/"><!-- Primary Meta Tags --><title>GrowGen | 给我整 | Windows 上使用 scrapy 抓取网页</title><meta name="title" content="GrowGen | 给我整 | Windows 上使用 scrapy 抓取网页"><meta name="description" content="过去一周，我在尝试在 Windows 上面使用 python，我会在这一篇文章中总结一下这一次体验的经验，代码已经发布到GitHub上面。

安装 python

本身 python 的版本就比较混乱，Windows 又提供了商店版，而且 ..."><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://growgen.xyz/tech/2020/02/04/windows-scrapy/"><meta property="og:title" content="GrowGen | 给我整 | Windows 上使用 scrapy 抓取网页"><meta property="og:description" content="过去一周，我在尝试在 Windows 上面使用 python，我会在这一篇文章中总结一下这一次体验的经验，代码已经发布到GitHub上面。

安装 python

本身 python 的版本就比较混乱，Windows 又提供了商店版，而且 ..."><meta property="og:image" content="https://growgen.xyz/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://growgen.xyz/tech/2020/02/04/windows-scrapy/"><meta property="twitter:title" content="GrowGen | 给我整 | Windows 上使用 scrapy 抓取网页"><meta property="twitter:description" content="过去一周，我在尝试在 Windows 上面使用 python，我会在这一篇文章中总结一下这一次体验的经验，代码已经发布到GitHub上面。

安装 python

本身 python 的版本就比较混乱，Windows 又提供了商店版，而且 ..."><meta property="twitter:image" content="https://growgen.xyz/blog-placeholder-1.jpg"><script>
      const getThemePreference = () => {
        const stored = localStorage?.getItem('theme')
        if (stored) {
          return stored
        }
        return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light'
      }
      const isDark = () => getThemePreference() === 'dark'
      document.documentElement.classList[isDark() ? 'add' : 'remove']('dark')
    
      if(localStorage) {
        const observer = new MutationObserver(() => {
          const isDark = document.documentElement.classList.contains('dark')
          localStorage.setItem('theme', isDark ? 'dark' : 'light')
        })
        observer.observe(document.documentElement, { attributes: true, attributeFilter: ['class'] })
      }
    </script><link rel="stylesheet" href="/_astro/_slug_.74c705b0.css" />
<link rel="stylesheet" href="/_astro/_slug_.28853c60.css" /></head><body class="min-h-full grid grid-cols-1" data-astro-cid-d3haqyqs><header class="h-16 sticky p-0 px-4 z-10 top-0  bg-background/95 backdrop-blur supports-[backdrop-filter]:bg-background/60" data-astro-cid-3ef6ksr2><nav class="flex items-center justify-between" data-astro-cid-3ef6ksr2><h2 data-astro-cid-3ef6ksr2><a href="/" data-astro-cid-3ef6ksr2>GrowGen | 给我整</a></h2><div class="flex items-center gap-4" data-astro-cid-3ef6ksr2><a href="/" data-astro-cid-3ef6ksr2 data-astro-cid-eimmu3lg>Home</a><a href="/all" data-astro-cid-3ef6ksr2 data-astro-cid-eimmu3lg>Blog</a><style>astro-island,astro-slot,astro-static-slot{display:contents}</style><script>(()=>{var e=async t=>{await(await t())()};(self.Astro||(self.Astro={})).load=e;window.dispatchEvent(new Event("astro:load"));})();;(()=>{var b=Object.defineProperty;var f=(c,o,i)=>o in c?b(c,o,{enumerable:!0,configurable:!0,writable:!0,value:i}):c[o]=i;var l=(c,o,i)=>(f(c,typeof o!="symbol"?o+"":o,i),i);var p;{let c={0:t=>m(t),1:t=>i(t),2:t=>new RegExp(t),3:t=>new Date(t),4:t=>new Map(i(t)),5:t=>new Set(i(t)),6:t=>BigInt(t),7:t=>new URL(t),8:t=>new Uint8Array(t),9:t=>new Uint16Array(t),10:t=>new Uint32Array(t)},o=t=>{let[e,r]=t;return e in c?c[e](r):void 0},i=t=>t.map(o),m=t=>typeof t!="object"||t===null?t:Object.fromEntries(Object.entries(t).map(([e,r])=>[e,o(r)]));customElements.get("astro-island")||customElements.define("astro-island",(p=class extends HTMLElement{constructor(){super(...arguments);l(this,"Component");l(this,"hydrator");l(this,"hydrate",async()=>{var d;if(!this.hydrator||!this.isConnected)return;let e=(d=this.parentElement)==null?void 0:d.closest("astro-island[ssr]");if(e){e.addEventListener("astro:hydrate",this.hydrate,{once:!0});return}let r=this.querySelectorAll("astro-slot"),a={},h=this.querySelectorAll("template[data-astro-template]");for(let n of h){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute("data-astro-template")||"default"]=n.innerHTML,n.remove())}for(let n of r){let s=n.closest(this.tagName);s!=null&&s.isSameNode(this)&&(a[n.getAttribute("name")||"default"]=n.innerHTML)}let u;try{u=this.hasAttribute("props")?m(JSON.parse(this.getAttribute("props"))):{}}catch(n){let s=this.getAttribute("component-url")||"<unknown>",y=this.getAttribute("component-export");throw y&&(s+=` (export ${y})`),console.error(`[hydrate] Error parsing props for component ${s}`,this.getAttribute("props"),n),n}await this.hydrator(this)(this.Component,u,a,{client:this.getAttribute("client")}),this.removeAttribute("ssr"),this.dispatchEvent(new CustomEvent("astro:hydrate"))});l(this,"unmount",()=>{this.isConnected||this.dispatchEvent(new CustomEvent("astro:unmount"))})}disconnectedCallback(){document.removeEventListener("astro:after-swap",this.unmount),document.addEventListener("astro:after-swap",this.unmount,{once:!0})}connectedCallback(){if(!this.hasAttribute("await-children")||document.readyState==="interactive"||document.readyState==="complete")this.childrenConnectedCallback();else{let e=()=>{document.removeEventListener("DOMContentLoaded",e),r.disconnect(),this.childrenConnectedCallback()},r=new MutationObserver(()=>{var a;((a=this.lastChild)==null?void 0:a.nodeType)===Node.COMMENT_NODE&&this.lastChild.nodeValue==="astro:end"&&(this.lastChild.remove(),e())});r.observe(this,{childList:!0}),document.addEventListener("DOMContentLoaded",e)}}async childrenConnectedCallback(){let e=this.getAttribute("before-hydration-url");e&&await import(e),this.start()}start(){let e=JSON.parse(this.getAttribute("opts")),r=this.getAttribute("client");if(Astro[r]===void 0){window.addEventListener(`astro:${r}`,()=>this.start(),{once:!0});return}Astro[r](async()=>{let a=this.getAttribute("renderer-url"),[h,{default:u}]=await Promise.all([import(this.getAttribute("component-url")),a?import(a):()=>()=>{}]),d=this.getAttribute("component-export")||"default";if(!d.includes("."))this.Component=h[d];else{this.Component=h;for(let n of d.split("."))this.Component=this.Component[n]}return this.hydrator=u,this.hydrate},e,this)}attributeChangedCallback(){this.hydrate()}},l(p,"observedAttributes",["props"]),p))}})();</script><astro-island uid="1831nl" prefix="r0" component-url="/_astro/DarkModeToggle.123dfc23.js" component-export="ModeToggle" renderer-url="/_astro/client.97c1142b.js" props="{&quot;data-astro-cid-3ef6ksr2&quot;:[0,true]}" ssr="" client="load" opts="{&quot;name&quot;:&quot;ModeToggle&quot;,&quot;value&quot;:true}" await-children=""><button class="inline-flex items-center justify-center whitespace-nowrap rounded-md text-sm font-medium ring-offset-background transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:pointer-events-none disabled:opacity-50 border border-input bg-background hover:bg-accent hover:text-accent-foreground h-10 w-10" type="button" id="radix-:r0R0:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="h-[1.2rem] w-[1.2rem] rotate-0 scale-100 transition-all dark:-rotate-90 dark:scale-0"><circle cx="12" cy="12" r="4"></circle><path d="M12 2v2"></path><path d="M12 20v2"></path><path d="m4.93 4.93 1.41 1.41"></path><path d="m17.66 17.66 1.41 1.41"></path><path d="M2 12h2"></path><path d="M20 12h2"></path><path d="m6.34 17.66-1.41 1.41"></path><path d="m19.07 4.93-1.41 1.41"></path></svg><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="absolute h-[1.2rem] w-[1.2rem] rotate-90 scale-0 transition-all dark:rotate-0 dark:scale-100"><path d="M12 3a6 6 0 0 0 9 9 9 9 0 1 1-9-9Z"></path></svg><span class="sr-only">Toggle theme</span></button><!--astro:end--></astro-island></div></nav></header><main class="min-h-full grid grid-cols-1 justify-items-center"><article class="markdown-body max-w-6xl"><h1 id="windows-上使用-scrapy-抓取网页">Windows 上使用 scrapy 抓取网页</h1>
<p>过去一周，我在尝试在 Windows 上面使用 python，我会在这一篇文章中总结一下这一次体验的经验，代码已经发布到<a href="https://github.com/gongbaodd/webScrapingStudy" rel="noopener noreferrer nofollow" target="_blank">GitHub</a>上面。</p>
<h2 id="安装-python">安装 python</h2>
<p>本身 python 的版本就比较混乱，Windows 又提供了商店版，而且 WSL 下面也可以安装 Linux 的 python，我都体验了一下。</p>
<ul>
<li>Windows 商店版，这个貌似就是为了教学使用，因为 Windows 目前比较尴尬，全局安装的包可能会有兼容性问题，但是因为商店版都运行在沙盒之下，基本上就没多少修改的可能了。</li>
<li>WSL 版本，这个版本体验的是纯正的 Linux，但是一定要注意，如果没安装 Xserver 就相当于没有图形界面。</li>
<li>x64 版本，这个问题在于安装文件的地址都跟了个 x64。</li>
<li>win32 版本，这个版本的问题比较小，除了 pyenv 需要单独下载 Windows 版和<a href="https://gongbaodd.github.io/tech/2020/01/06/%E4%BF%AE%E5%A4%8DWindows%E4%B8%8B%E6%89%93%E5%BC%80Jupyter%E6%97%B6%E6%8A%A5NotImplementError.html" rel="noopener noreferrer nofollow" target="_blank">jupyter 报错</a>，还没碰到其他问题。</li>
</ul>
<h2 id="pyenv">pyenv</h2>
<p>介于 python 大版本兼容性，个人认为要安装一个版本管理器。因为习惯于 JavaScript 工作环境，我肯定会寻找类似于 nvm 的映射就是 pyenv，在 Windows 下面可以通过 chocolatey 安装。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#B392F0">sudo</span><span style="color:#9ECBFF"> choco</span><span style="color:#9ECBFF"> install</span><span style="color:#9ECBFF"> pyenv-win</span></span></code></pre>
<p>下面几个命令是最常用的。</p>
<ul>
<li><code>pyenv install -l</code>查看可以安装的 python 版本号。</li>
<li><code>pyenv local install 3.8.0</code>在项目中安装 3.8.0 版本（会在项目目录增加.python-version 文件）。</li>
<li><code>pyenv version</code>查看现在的 python 版本。</li>
<li><code>pyenv versions</code>查看安装过的 python 版本。</li>
</ul>
<p>win10 上了一个新功能，控制台会引导 python 到应用商店，在“设置>应用和功能>应用执行名”中可以勾掉这个功能</p>
<h2 id="virtualenv">virtualenv</h2>
<p>python 的包管理其实很差，都是放到 global 下面，这就导致多个项目可能都用同一个依赖。那么如何实现每个项目都有自己的依赖呢？这就靠 virtualenv。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#B392F0">pip</span><span style="color:#9ECBFF"> install</span><span style="color:#9ECBFF"> virtualenv</span></span></code></pre>
<p>如下命令最常用</p>
<ul>
<li><code>virtualenv [venv folder name]</code>新建虚拟环境文件夹。</li>
<li><code>source [venv folder name]/Scripts/activate</code>启动虚拟环境（在 Linux 下面是 bin/activate）。</li>
<li><code>deactivate</code>关闭虚拟环境（这个在 Linux 会比较常用）。</li>
</ul>
<h2 id="scrapy">scrapy</h2>
<p>scrapy 是一个 python 的爬虫框架，使用 pip 可以安装 scrapy。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#B392F0">pip</span><span style="color:#9ECBFF"> install</span><span style="color:#9ECBFF"> scrapy</span></span></code></pre>
<p>下面是 scrapy 用的比较多的几个命令</p>
<ul>
<li><code>scrapy startproject [project name]</code>新建项目。</li>
<li><code>scrapy crawl [spider name] -o [output file]</code>爬取页面并输出结果到文件。</li>
</ul>
<p>scrapy 的概念比较多，包括 spider、pipeline、middleware 等等，但个人看来基本上看完<a href="https://docs.scrapy.org/en/latest/intro/tutorial.html#our-first-spider" rel="noopener noreferrer nofollow" target="_blank">tutorial</a>就可以上手了。</p>
<h3 id="scrapy-shell">scrapy shell</h3>
<p>执行<code>scrapy shell [url]</code>可以以命令形式使用 scrapy。</p>
<ul>
<li><code>fetch('http://xxx.com')</code>爬取页面</li>
<li><code>view(response)</code>浏览爬取的页面</li>
<li><code>response.css('a::text').extract()</code>析取页面中链接的文字列表</li>
<li><code>response.css('a::attr(href)')</code>析取页面中链接列表</li>
</ul>
<h3 id="发起-xmlhttp-请求">发起 Xmlhttp 请求</h3>
<p>使用<a href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.FormRequest" rel="noopener noreferrer nofollow" target="_blank">Scrapy.FormRequest</a>发起请求，接收到结果可以使用[response.body_as_unicode()]解析 JSON 为字典。</p>
<h3 id="splash">splash</h3>
<p>截至目前，scrapy 都只能渲染非 JavaScript 运行的页面，但是借助 splash 就可以解析 JavaScript 了。我们使用 docker 可以尝试一下 splash。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#B392F0">docker</span><span style="color:#9ECBFF"> pull</span><span style="color:#9ECBFF"> scrapinghub/splash</span></span>
<span class="line"><span style="color:#B392F0">docker</span><span style="color:#9ECBFF"> run</span><span style="color:#79B8FF"> -p</span><span style="color:#79B8FF"> 8050</span><span style="color:#9ECBFF">:8050</span><span style="color:#9ECBFF"> scrapinghub/splash</span></span></code></pre>
<p>访问 localhost:8050 即可访问 splash。通过安装<code>scrapy-splash</code>可以在 scrapy 中使用 splash，具体安装步骤<a href="https://github.com/scrapy-plugins/scrapy-splash" rel="noopener noreferrer nofollow" target="_blank">官网</a>已经很详细在此不做赘述。</p>
<h2 id="scrapinghub">Scrapinghub</h2>
<p>Scrapinghub 是一个基于 scrapy 的云服务，可以将自己的爬虫部署到该平台。<a href="https://support.scrapinghub.com/support/solutions/articles/22000200667-running-a-scrapy-spider" rel="noopener noreferrer nofollow" target="_blank">这里</a>有个工具可以帮助部署（当然通过链接 GitHub 可以做到 master 部署）。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#B392F0">pip</span><span style="color:#9ECBFF"> install</span><span style="color:#9ECBFF"> shub</span></span></code></pre>
<h3 id="解决依赖">解决依赖</h3>
<p>爬虫上传到 Scrapinghub 之后，会部署失败，可能源于以下两点。</p>
<ul>
<li>scrapinghub 使用的是 python2</li>
<li>部份依赖没有安装</li>
</ul>
<p>以上两点可以通过修改 scrapinghub.yml 完成</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span style="color:#85E89D">projects</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#85E89D">  default</span><span style="color:#E1E4E8">: </span><span style="color:#79B8FF">427692</span></span>
<span class="line"><span style="color:#85E89D">stacks</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#85E89D">  default</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">scrapy:1.8-py3</span></span>
<span class="line"><span style="color:#85E89D">requirements</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#85E89D">  file</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">requirements.txt</span></span></code></pre>
<p>通过<code>pip freeze</code>能够列举出目前环境下的所有包，需要挑出可能缺少的依赖写在 requirements.txt 里面（没错这一步只能人工完成，不要妄想把所有包都写进去）。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span>beautifulsoup4==4.8.2</span></span>
<span class="line"><span>feedparser===5.2.1</span></span>
<span class="line"><span>scrapy-splash==0.7.2</span></span></code></pre>
<h2 id="单元测试">单元测试</h2>
<p>使用 python 自带的 unittest 模块以及 pytest 可以对代码进行单元测试。可以参考我代码中的<a href="https://github.com/gongbaodd/webScrapingStudy/tree/master/test/test_spider" rel="noopener noreferrer nofollow" target="_blank">测试</a>。</p>
<p>执行 pytest 的时候会出现找不到模块的问题，可以按照如下方式重置根地址位置。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0"><code><span class="line"><span>python -m pytest [file path]</span></span></code></pre>
<h2 id="代码优化和格式化">代码优化和格式化</h2>
<p>这里比较爽了，如果用的是 vscode，在第一次格式化代码的时候，vscode 就会安装格式化工具。</p>
<h2 id="pre-commit">pre-commit</h2>
<p>pre-commit 是一个 git 钩子工具，简单说，当本地代码不满足要求的时候，利用这个工具自动格式化代码或者阻止用户提交代码。可以参考<a href="https://pre-commit.com/" rel="noopener noreferrer nofollow" target="_blank">官网配置</a>。</p>
<h2 id="包健康检查">包健康检查</h2>
<p>目前没在 python 找到一个类似于 yarn audit 的东西，到那时找到了一个<a href="https://snyk.io" rel="noopener noreferrer nofollow" target="_blank">SNYK</a>是一个跨语言的包健康检查工具，但是貌似还有 bug，暂时先裸奔好了。</p>
<h2 id="持续集成">持续集成</h2>
<p>目前我是用 Travis 做集成，配置文件可参考<a href="https://github.com/gongbaodd/webScrapingStudy/blob/master/.travis.yml" rel="noopener noreferrer nofollow" target="_blank">此文件</a>。</p>
<h2 id="兼容性处理">兼容性处理</h2>
<p>另外还找到一个 python 版本兼容测试工具，考虑到使用 python 命令的人自己的 python 版本并不确定，<a href="https://pypi.org/project/tox/" rel="noopener noreferrer nofollow" target="_blank">tox</a>则是用来测试 py 是否兼容某些 python 的版本。</p></article><footer data-astro-cid-sz7xmlte>
&copy; 2023 宫不上, built with <span class="heart" data-astro-cid-sz7xmlte>❤️</span>. All rights reserved.
</footer></main></body></html>